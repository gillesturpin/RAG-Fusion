# ğŸ—ï¸ Architecture RAG Agent

## Vue d'ensemble

Ce projet implÃ©mente un **RAG Agent** basÃ© sur le tutoriel officiel LangChain ([RAG Agent Tutorial](https://python.langchain.com/docs/tutorials/rag_agent/)).

## ğŸ“Š Architecture Globale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            User Question                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚    RAG Agent     â”‚
          â”‚  (with Memory)   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
             [Intelligent]
             [k=4 docs]
            [Conversational]
```

---

## ğŸ”§ RAG Agent - Architecture DÃ©taillÃ©e

### Flow Diagram
```
User Question
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LangGraph Workflow    â”‚
â”‚   (with InMemorySaver)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLM Router    â”‚ â† DÃ©cide si retrieval nÃ©cessaire
â”‚  (Claude 4.5)   â”‚    via tool calling
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”œâ”€â”€â”€ Tool Call â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                  â”‚   Retriever   â”‚
      â”‚                  â”‚    (k=4)      â”‚
      â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                         â”‚
      â”‚                         â–¼
      â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                  â”‚   Documents  â”‚
      â”‚                  â”‚  + Metadata  â”‚
      â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                         â”‚
      â””â”€â”€â”€ Direct â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   Generate   â”‚
                         â”‚    Answer    â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  Save State  â”‚
                         â”‚  (Memory)    â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CaractÃ©ristiques Principales

- **Framework** : LangGraph `StateGraph`
- **LLM** : Claude Sonnet 4.5 (`claude-sonnet-4-5-20250929`)
- **Retrieval** : Optionnel (LLM dÃ©cide via tool calling)
- **Documents** : k=4 (similarity search)
- **MÃ©moire** : InMemorySaver (conversation persistante par thread_id)
- **Streaming** : Support SSE (Server-Sent Events)
- **Flow** : Question â†’ Route â†’ (Retrieve?) â†’ Generate â†’ Save

### ImplÃ©mentation Core

**Fichier** : `backend/rags/rag_agent.py`

```python
class RAGAgent:
    def __init__(self, vectorstore, checkpointer=None):
        # Use InMemorySaver for conversation memory
        self.checkpointer = checkpointer or InMemorySaver()

        # Create retrieve tool
        @tool
        def retrieve(query: str):
            """Retrieve information related to a query."""
            retrieved_docs = self.vectorstore.similarity_search(query, k=4)
            # Format documents with metadata
            serialized = "\n\n".join(
                f"Source: {doc.metadata}\nContent: {doc.page_content}"
                for doc in retrieved_docs
            )
            return serialized

        # Bind tools to model
        self.model_with_tools = self.model.bind_tools([retrieve])

        # Build LangGraph workflow
        self.graph = self._build_graph()

    def _build_graph(self):
        workflow = StateGraph(MessagesState)

        # Add nodes
        workflow.add_node("agent", self._call_model)
        workflow.add_node("tools", ToolNode([retrieve]))

        # Conditional routing
        def should_continue(state):
            last_message = state["messages"][-1]
            if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
                return "tools"  # LLM wants to retrieve
            return END  # LLM answers directly

        workflow.add_conditional_edges("agent", should_continue)
        workflow.add_edge("tools", "agent")  # Loop back after retrieval

        # Compile with memory
        return workflow.compile(checkpointer=self.checkpointer)

    def invoke(self, question: str, thread_id: str = None):
        config = {"configurable": {"thread_id": thread_id}} if thread_id else {}
        result = self.graph.invoke(
            {"messages": [HumanMessage(content=question)]},
            config
        )
        return {
            "answer": result["messages"][-1].content,
            "messages": result["messages"],
            "used_retrieval": any(msg.type == "tool" for msg in result["messages"]),
            "thread_id": thread_id
        }
```

### Nodes du Graph

#### 1. **agent** (LLM Router)
- ReÃ§oit la question + historique (mÃ©moire)
- DÃ©cide : retrieval nÃ©cessaire ou non ?
- Retourne : rÃ©ponse directe OU appel au tool `retrieve`

#### 2. **tools** (Retriever)
- ExÃ©cute `similarity_search(k=4)` sur ChromaDB
- Formate les documents avec mÃ©tadonnÃ©es
- Retourne le contexte au LLM

#### 3. **Conditional Edge**
- Si `tool_calls` prÃ©sent â†’ va vers `tools`
- Sinon â†’ END (rÃ©ponse finale)

### MÃ©moire Conversationnelle

**InMemorySaver** stocke l'historique par `thread_id` :

```python
# Premier message (thread-1)
agent.invoke("My name is Alice", thread_id="thread-1")

# DeuxiÃ¨me message (mÃªme thread)
agent.invoke("What is my name?", thread_id="thread-1")
# RÃ©ponse : "Your name is Alice" âœ…

# Nouveau thread
agent.invoke("What is my name?", thread_id="thread-2")
# RÃ©ponse : "I don't know" (pas de mÃ©moire) âœ…
```

### Message Trimming

Pour Ã©viter de dÃ©passer la limite de contexte :

```python
def trim_messages(messages):
    """Keep only the last 10 messages to fit context window."""
    if len(messages) <= 10:
        return messages
    # Keep first (system) and last 9 messages
    return [messages[0]] + messages[-9:]
```

### Prompt System

```python
SystemMessage(
    "You have access to a tool that retrieves context from documents. "
    "Use the tool to help answer user queries. "
    "IMPORTANT: Provide COMPLETE and COMPREHENSIVE answers with ALL details. "
    "Do not omit any information. Use proper Markdown formatting."
)
```

### Cas d'Usage

âœ… **Optimal pour** :
- Questions nÃ©cessitant contexte documentaire
- Conversations multi-tours
- Applications nÃ©cessitant mÃ©moire
- Chatbots conversationnels
- Questions mixtes (in/out context)

âŒ **Moins optimal pour** :
- Questions ultra-simples (overhead du graph)
- Batch processing sans mÃ©moire
- Cas nÃ©cessitant grading strict des documents

### Output Format

```json
{
  "answer": "La rÃ©ponse gÃ©nÃ©rÃ©e avec contexte",
  "messages": [
    {"role": "user", "content": "Question"},
    {"role": "assistant", "content": "Tool call"},
    {"role": "tool", "content": "Documents..."},
    {"role": "assistant", "content": "RÃ©ponse finale"}
  ],
  "used_retrieval": true,
  "thread_id": "thread-abc123"
}
```

---

## ğŸ“ˆ MÃ©triques de Performance

| MÃ©trique | Valeur Typique |
|----------|----------------|
| **Latence moyenne** | 2-5s |
| **Appels LLM par requÃªte** | 1-2 |
| **Documents rÃ©cupÃ©rÃ©s** | k=4 |
| **MÃ©moire max** | 10 messages |
| **CoÃ»t estimÃ© par requÃªte** | ~$0.001 |

### Breakdown Latence

- **Sans retrieval** : ~1-2s (rÃ©ponse directe)
- **Avec retrieval** : ~3-5s (similarity search + gÃ©nÃ©ration)
- **Conversation** : +0.5s (chargement historique)

---

## ğŸ”§ Configuration

### Variables d'Environnement

```bash
# Requis
ANTHROPIC_API_KEY=sk-ant-...  # Claude Sonnet 4.5

# Optionnel
TAVILY_API_KEY=tvly-...  # Web search (non utilisÃ© actuellement)
```

### ParamÃ¨tres Ajustables

**Dans `rag_agent.py` :**

```python
# LLM Configuration
model = "claude-sonnet-4-5-20250929"
model_provider = "anthropic"

# Retrieval
k = 4  # Nombre de documents Ã  rÃ©cupÃ©rer

# Memory
max_messages = 10  # Historique conservÃ© par conversation

# Embeddings
embedding_model = "sentence-transformers/all-MiniLM-L6-v2"
```

**Dans `api/main.py` :**

```python
# Text Splitting (upload)
chunk_size = 2000
chunk_overlap = 400

# Streaming
word_delay = 0.03  # 30ms entre chaque mot (effet visuel)
```

---

## ğŸ“š Ressources

### Documentation Officielle
- [LangChain RAG Agent Tutorial](https://python.langchain.com/docs/tutorials/rag_agent/) - Base de ce projet
- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/) - Framework utilisÃ©
- [Anthropic Claude API](https://docs.anthropic.com/) - LLM provider

### Fichiers du Projet
- `backend/rags/rag_agent.py` - ImplÃ©mentation core
- `backend/api/main.py` - FastAPI endpoints
- `test_memory.py` - Tests de la mÃ©moire conversationnelle

---

## ğŸ§ª Tests

### Test de la MÃ©moire

```bash
python test_memory.py
```

**RÃ©sultats attendus** :
- âœ… Thread diffÃ©rent â†’ pas de mÃ©moire
- âœ… MÃªme thread â†’ mÃ©moire fonctionnelle
- âœ… Trimming â†’ garde 10 derniers messages

### Test de l'API

```bash
# Lancer le serveur
cd backend/api && python main.py

# Tester (autre terminal)
curl -X POST http://localhost:8000/api/rag_agent \
  -H "Content-Type: application/json" \
  -d '{"question": "What is RAG?", "thread_id": "test-123"}'
```

---

## ğŸš€ Roadmap

### Actuellement ImplÃ©mentÃ©
- âœ… RAG Agent avec tool calling
- âœ… MÃ©moire conversationnelle (InMemorySaver)
- âœ… Streaming SSE
- âœ… Upload documents (PDF/TXT/MD/DOCX)
- âœ… Message trimming
- âœ… ChromaDB vectorstore

### AmÃ©liorations Possibles
- â³ Agentic RAG avec grading (comme dans tutoriel avancÃ©)
- â³ PostgreSQL checkpointer (persistance DB)
- â³ Hybrid search (dense + sparse)
- â³ Citation tracking
- â³ Token usage tracking rÃ©el
- â³ MÃ©triques d'Ã©valuation (RAGAS)